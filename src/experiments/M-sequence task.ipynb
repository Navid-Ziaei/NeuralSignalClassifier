{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-29T07:08:54.473014Z",
     "start_time": "2024-08-29T07:08:49.231016Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "from src.settings import Paths, Settings\n",
    "from src.data_loader import CLEARDataLoader\n",
    "from ieeg_data_loader.data import iEEGDataLoader\n",
    "from ieeg_data_loader.visualization import plot_continuous_signal\n",
    "from src.feature_extraction import FeatureExtractor\n",
    "from src.data_preprocess import DataPreprocessor\n",
    "from src.utils import *\n",
    "from src.model.utils.training_utils import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load settings from settings.yaml\n",
   "id": "37c89aeefc2f5e57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T07:08:54.572086Z",
     "start_time": "2024-08-29T07:08:54.474072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "settings = Settings()  # Initialize settings object\n",
    "settings.load_settings()  # Load settings from a JSON file\n",
    "settings.dataset = 'clear'\n",
    "settings.patient = ['p09']"
   ],
   "id": "2fb70aee183e2077",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set up paths for data",
   "id": "57e5266770d7629c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T07:08:54.672276Z",
     "start_time": "2024-08-29T07:08:54.573090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paths = Paths(settings)  # Initialize paths object with loaded settings\n",
    "paths.load_device_paths()  # Load device-specific paths\n",
    "paths.create_paths()  # Create any necessary file paths"
   ],
   "id": "1d360907344e5e1e",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize Data before pre-processing",
   "id": "4f336c6764cd8b96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T07:08:57.536524Z",
     "start_time": "2024-08-29T07:08:54.673283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load EEG dataset using configured settings and paths\n",
    "dataset = CLEARDataLoader(paths=paths, settings=settings)\n",
    "dataset.load_data(patient_ids=settings.patient)  # Load EEG data for specified patients\n",
    "data_loader = iEEGDataLoader(patient=settings.patient,\n",
    "                                 target_class='color',\n",
    "                                 prepared_dataset_path=paths.raw_dataset_path,\n",
    "                                 task=settings.dataset_task,\n",
    "                                 file_format='npy')\n",
    "dataset_list = data_loader.load_data()\n",
    "\n"
   ],
   "id": "6cc059d13dd3853f",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T07:09:44.624845Z",
     "start_time": "2024-08-29T07:09:14.105656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for patient in settings.patient:\n",
    "    continuous_signal, continuous_indicator = dataset_list[1].epoched_to_continuous(patient=patient, \n",
    "                                                                                    task=settings.dataset_task,\n",
    "                                                                                    debug=False,\n",
    "                                                                                    save_path=paths.path_result)\n",
    "    \n",
    "    plot_continuous_signal(continuous_signal, continuous_indicator,\n",
    "                           channel_names=dataset_list[1].channel_name,\n",
    "                           channel_number=15, \n",
    "                           task=settings.dataset_task, \n",
    "                           save_path=None,\n",
    "                           title_fontsize=48, label_fontsize=28, legend_fontsize=24, tick_fontsize=18)"
   ],
   "id": "ee3dc526f057d532",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T07:09:44.742695Z",
     "start_time": "2024-08-29T07:09:44.626852Z"
    }
   },
   "cell_type": "code",
   "source": "continuous_signal.shape",
   "id": "c67e7015863c08ec",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the continuous signals",
   "id": "e59b80fdbeda6713"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T07:19:32.941454Z",
     "start_time": "2024-08-29T07:12:06.903175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for patient in settings.patient:\n",
    "    save_path = paths.eda_results + f'Continuous_signals/{patient}/{settings.dataset_task}/'\n",
    "    if os.path.exists(save_path) is False:\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "        for ch in tqdm(range(len(dataset_list[1].channel_name))):\n",
    "            plot_continuous_signal(continuous_signal, continuous_indicator,\n",
    "                                       channel_names=dataset_list[1].channel_name,\n",
    "                                       channel_number=ch, \n",
    "                                       task=settings.dataset_task, \n",
    "                                       save_path=save_path,\n",
    "                                   title_fontsize=48, label_fontsize=28, legend_fontsize=24, tick_fontsize=18)"
   ],
   "id": "eced80599250188b",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extract Features",
   "id": "49693f405a0fb91e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features_raw_df_list = []\n",
    "for patient in settings.patient:\n",
    "    # Load EEG dataset using configured settings and paths\n",
    "    dataset = CLEARDataLoader(paths=paths, settings=settings)\n",
    "            \n",
    "\n",
    "    dataset.load_data(patient_ids=patient)  # Load EEG data for specified patients        \n",
    "\n",
    "    # Preprocess the loaded dataset\n",
    "    preprocessing_configs = {\n",
    "        #'remove_baseline': {'normalize': False, 'baseline_t_min': -1000},\n",
    "        # 'low_pass_filter': {'cutoff': 45, 'order': 5}\n",
    "    }\n",
    "    data_preprocessor = DataPreprocessor(paths=paths, settings=settings)  # Initialize data preprocessor\n",
    "    dataset = data_preprocessor.preprocess(dataset, preprocessing_configs)\n",
    "    \n",
    "    # Extract features from the preprocessed dataset\n",
    "    feature_extraction_configs = {\n",
    "        'time_n200': {'start_time': 150, 'end_time': 250},\n",
    "        'time_p300': {'start_time': 250, 'end_time': 550},\n",
    "        'time_post_p300': {'start_time': 550, 'end_time': 750},\n",
    "        'frequency1': {'time_start': 0, 'end_time': 500},\n",
    "        'frequency2': {'time_start': 250, 'end_time': 800}\n",
    "    }\n",
    "    feature_extractor = FeatureExtractor(paths=paths, settings=settings)  # Initialize feature extractor\n",
    "    feature_extractor.extract_features(dataset,\n",
    "                                       feature_extraction_configs)  # Extract relevant features from the dataset\n",
    "    features_raw_df, *_ = feature_extractor.get_feature_array(dataset)\n",
    "    if settings.save_features is True:\n",
    "        features_raw_df.to_csv(paths.feature_path + f\"feature_{settings.dataset}_{patient}.csv\", index=False)\n",
    "\n",
    "features_raw_df_list.append(features_raw_df)"
   ],
   "id": "13e379426ef26ce9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.model.utils.training_utils import train_k_fold\n",
    "train_k_fold(features_raw_df_list=features_raw_df_list, \n",
    "             target='target_0_0', \n",
    "             settings=settings, \n",
    "             paths=paths)"
   ],
   "id": "d0942c9a93ff900",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Test Split",
   "id": "969007caa08d9e37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "drop_columns = get_drop_columns(settings)\n",
    "results_logger = ResultList(method_list=settings.method_list, metric_list=settings.metric_list)\n",
    "\n"
   ],
   "id": "f9aaefac49fd834a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Select the patient",
   "id": "12e274b5b2d28ebd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "patient_id = 0\n",
    "features_df = features_raw_df_list[patient_id]\n",
    "print(f\"============ Subject {patient_id} ({settings.patient[patient_id]}) from {len(features_raw_df_list)} ============ \\n\")\n",
    "labels_array, target_columns = get_labels_clear(features_df, settings)\n",
    "\n"
   ],
   "id": "1d5da646ae5c6735",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train for just one fold",
   "id": "aaf8c670e362f3df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_index, test_index = train_test_split(range(len(features_df)), test_size=0.2, random_state=42)\n",
    "\n",
    "features_matrix, selected_features, patients_ids, patients_files = \\\n",
    "        get_selected_features(features_df = features_df.copy(), \n",
    "                              settings = settings, \n",
    "                              paths = paths, \n",
    "                              fold_idx = 0, \n",
    "                              train_index = train_index,\n",
    "                              target_columns_drop=drop_columns)\n",
    "\n"
   ],
   "id": "6de73665d85fc1dc",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "selected_features",
   "id": "65a6a3794a16d554",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "selected_features.keys()",
   "id": "db8dc5b6dd067d27",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "id": "c1762c460ee6e2ae",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for key in list(selected_features.keys())[:1]:\n",
    "    \n",
    "    df_single_event  = features_df[selected_features[key]].copy()\n",
    "    labels_array_single_event = features_df[key].values\n",
    "    if settings.feature_transformation is not None:\n",
    "        if settings.feature_transformation.lower() == 'normalize':\n",
    "            df_single_event = df_single_event.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        elif settings.feature_transformation.lower() == 'standardize':\n",
    "            df_single_event = df_single_event.apply(lambda x: (x - x.mean()) / x.std())\n",
    "        else:\n",
    "            raise ValueError(\"The transformation is not defined\")\n",
    "\n",
    "    features_matrix_single_event = df_single_event.values\n",
    "    \n",
    "    data_train, data_test = features_matrix_single_event[train_index], features_matrix_single_event[test_index]\n",
    "    labels_train, labels_test = labels_array_single_event[train_index], labels_array_single_event[test_index]\n",
    "    pid_train, pid_test = patients_ids[train_index], patients_ids[test_index]\n",
    "    \n",
    "    results, group_result = train_xgb(data_train, labels_train, data_test, labels_test, paths)"
   ],
   "id": "a031bb2ba9e1a83d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "settings.feature_transformation",
   "id": "dce701ec2e112ad4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_one_hot = labels_array[:, 10]\n",
    "data_train, data_test = features_matrix[train_index], features_matrix[test_index]\n",
    "labels_train, labels_test = labels_array[train_index], labels_array[test_index]\n",
    "y_train, y_test = y_one_hot[train_index], y_one_hot[test_index]\n",
    "pid_train, pid_test = patients_ids[train_index], patients_ids[test_index]"
   ],
   "id": "2e49c8290ee8c9ad",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "method = settings.method_list[0]\n",
    "print(f\"=========== Train Subject {patient_id} ({settings.patient[patient_id]}) from {len(features_raw_df_list)} Model {method} =========== \\n\")\n",
    "\n",
    "if method.lower() == 'xgboost':\n",
    "    results, group_result = train_xgb(data_train, labels_train, data_test, labels_test, paths)\n",
    "elif method.lower() == 'ldgd':\n",
    "    results, group_result = train_ldgd(data_train, labels_train, data_test, labels_test,\n",
    "                         y_train, y_test,\n",
    "                         settings, paths)\n",
    "elif method.lower() == 'fast_ldgd':\n",
    "    results, group_result = train_fast_ldgd(data_train, labels_train, data_test, labels_test,\n",
    "                              y_train, y_test,\n",
    "                              settings, paths,\n",
    "                              use_validation=True)\n",
    "else:\n",
    "    raise ValueError(\"Method should be 'xgboost' or 'ldgd'\")"
   ],
   "id": "191292efec94e6e1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training using K-Fold Cross Validation",
   "id": "e0a849f1d28ca074"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the KFold cross-validator\n",
    "if isinstance(settings.cross_validation_mode, int):\n",
    "    kf = StratifiedKFold(n_splits=settings.cross_validation_mode, shuffle=True, random_state=42)\n",
    "elif isinstance(settings.cross_validation_mode, str) and settings.cross_validation_mode == 'order':\n",
    "    kf = None\n",
    "else:\n",
    "    raise ValueError(\"cross_validation_mode should be number of folds or be 'block' for block based\")\n",
    "\n",
    "if kf is None and settings.cross_validation_mode == 'order':\n",
    "    num_trials = labels_array.shape[0]\n",
    "    trial_idx = np.arange(num_trials)\n",
    "    fold_idx = np.int16(10*trial_idx / num_trials)\n",
    "    folds = [(np.where(fold_idx != fold)[0], np.where(fold_idx == fold)[0]) for fold in np.unique(fold_idx)]\n",
    "else:\n",
    "    folds = kf.split(features_df, labels_array)\n",
    "# Perform cross-validation\n",
    "fold_results = {method: [] for method in settings.method_list}\n",
    "fold_results_group = {method: [] for method in settings.method_list}\n",
    "for fold_idx, (train_index, test_index) in enumerate(folds):\n",
    "    paths.create_fold_path(fold_idx)\n",
    "    \n",
    "    # select features\n",
    "    features_matrix, selected_features, patients_ids, patients_files = \\\n",
    "        get_selected_features(features_df.copy(), settings, paths,\n",
    "                              fold_idx, train_index, train_index,\n",
    "                              target_columns_drop=drop_columns)\n",
    "    \n",
    "    data_train, data_test = features_matrix[train_index], features_matrix[test_index]\n",
    "    labels_train, labels_test = labels_array[train_index], labels_array[test_index]\n",
    "    y_train, y_test = y_one_hot[train_index], y_one_hot[test_index]\n",
    "    pid_train, pid_test = patients_ids[train_index], patients_ids[test_index]\n",
    "    \n",
    "    print(f\"=========== Train Subject {patient_id} ({settings.patient[patient_id]}) \"\n",
    "                  f\"from {len(features_raw_df_list)} Fold {fold_idx} Model {method} =========== \\n\")\n",
    "    if method.lower() == 'xgboost':\n",
    "        results, group_result = train_xgb(data_train, labels_train, data_test, labels_test, paths)\n",
    "    elif method.lower() == 'ldgd':\n",
    "        results, group_result = train_ldgd(data_train, labels_train, data_test, labels_test,\n",
    "                             y_train, y_test,\n",
    "                             settings, paths)\n",
    "    elif method.lower() == 'fast_ldgd':\n",
    "        results, group_result = train_fast_ldgd(data_train, labels_train, data_test, labels_test,\n",
    "                                  y_train, y_test,\n",
    "                                  settings, paths,\n",
    "                                  use_validation=True)\n",
    "    else:\n",
    "        raise ValueError(\"Method should be 'xgboost' or 'ldgd'\")\n",
    "\n",
    "    fold_results[method].append(results)\n",
    "    fold_results_group[method].append(group_result)"
   ],
   "id": "21eea0520f1c4e10",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "baee5b6a455b154d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "certain = []\n",
    "all_patient_group_results = {method: [] for method in settings.method_list}\n",
    "for patient_id, features_raw_df in enumerate(features_raw_df_list):\n",
    "    print(f\"============ Subject {patient_id} ({settings.patient[patient_id]}) from {len(features_raw_df_list)} ============ \\n\")\n",
    "    # select patient\n",
    "    # select patient\n",
    "    columns_to_remove = [col for col in features_raw_df.columns if \"EX\" in col]\n",
    "    features_df = features_raw_df.drop(columns=columns_to_remove)\n",
    "\n",
    "    # select labels\n",
    "    y_one_hot, labels_array, unique_pids, patients_files, features_df = get_labels(features_df, settings)\n",
    "\n",
    "    # Get the features matrix and labels from the raw features DataFrame\n",
    "    results_logger.add_subject(unique_pids, patients_files)\n",
    "\n",
    "    # Add the result path for this subject\n",
    "    paths.create_subject_paths(patients_files)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    fold_results = {method: [] for method in settings.method_list}\n",
    "    fold_results_group = {method: [] for method in settings.method_list}\n",
    "\n",
    "    if kf is None and settings.cross_validation_mode == 'order':\n",
    "        num_trials = labels_array.shape[0]\n",
    "        trial_idx = np.arange(num_trials)\n",
    "        fold_idx = np.int16(10*trial_idx / num_trials)\n",
    "        folds = [(np.where(fold_idx != fold)[0], np.where(fold_idx == fold)[0]) for fold in np.unique(fold_idx)]\n",
    "    else:\n",
    "        folds = kf.split(features_df, labels_array)\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(folds):\n",
    "\n",
    "        paths.create_fold_path(fold_idx)\n",
    "\n",
    "        # select features\n",
    "        features_matrix, selected_features, patients_ids, patients_files = \\\n",
    "            get_selected_features(features_df.copy(), settings, paths,\n",
    "                                  fold_idx, train_index, train_index,\n",
    "                                  target_columns_drop=drop_columns)\n",
    "\n",
    "        data_train, data_test = features_matrix[train_index], features_matrix[test_index]\n",
    "        labels_train, labels_test = labels_array[train_index], labels_array[test_index]\n",
    "        y_train, y_test = y_one_hot[train_index], y_one_hot[test_index]\n",
    "        pid_train, pid_test = patients_ids[train_index], patients_ids[test_index]\n",
    "\n",
    "        for method in settings.method_list:\n",
    "            print(f\"=========== Train Subject {patient_id} ({settings.patient[patient_id]}) \"\n",
    "                  f\"from {len(features_raw_df_list)} Fold {fold_idx} Model {method} =========== \\n\")\n",
    "            if method.lower() == 'xgboost':\n",
    "                results, group_result = train_xgb(data_train, labels_train, data_test, labels_test, paths)\n",
    "            elif method.lower() == 'ldgd':\n",
    "                results, group_result = train_ldgd(data_train, labels_train, data_test, labels_test,\n",
    "                                     y_train, y_test,\n",
    "                                     settings, paths)\n",
    "            elif method.lower() == 'fast_ldgd':\n",
    "                results, group_result = train_fast_ldgd(data_train, labels_train, data_test, labels_test,\n",
    "                                          y_train, y_test,\n",
    "                                          settings, paths,\n",
    "                                          use_validation=True)\n",
    "            else:\n",
    "                raise ValueError(\"Method should be 'xgboost' or 'ldgd'\")\n",
    "\n",
    "            fold_results[method].append(results)\n",
    "            fold_results_group[method].append(group_result)\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "    # Compute average scores\n",
    "    for method in settings.method_list:\n",
    "        for metric in settings.metric_list:\n",
    "            avg_score = np.mean([result[metric] for result in fold_results[method]])\n",
    "            std_score = np.std([result[metric] for result in fold_results[method]])\n",
    "            results_logger.update_result(method, metric, avg_score, std_score)\n",
    "            print(f\"Method {method}: {metric}: {avg_score} +- {std_score}\")\n",
    "\n",
    "    for key in fold_results.keys():\n",
    "        df = pd.DataFrame(fold_results[key])\n",
    "        df.to_csv(paths.results_base_path + f'{key}_results.csv', index=False)\n",
    "\n",
    "        # group base\n",
    "        # Extract true values and predictions from the given data\n",
    "        true_values = []\n",
    "        predictions = []\n",
    "\n",
    "        for gp_result in fold_results_group[key]:\n",
    "            for true_value, predicted_value in gp_result.items():\n",
    "                true_values.append(true_value)\n",
    "                predictions.append(predicted_value)\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        true_values = np.array(true_values)\n",
    "        predictions = np.array(predictions)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        grp_accuracy = accuracy_score(true_values, predictions.round())\n",
    "        grp_precision = precision_score(true_values, predictions.round(), average='binary')\n",
    "        grp_recall = recall_score(true_values, predictions.round(), average='binary')\n",
    "        grp_f1 = f1_score(true_values, predictions.round(), average='binary')\n",
    "        grp_auc = roc_auc_score(true_values, predictions)\n",
    "\n",
    "        group_result = {\n",
    "            'accuracy': grp_accuracy,\n",
    "            'precision': grp_precision,\n",
    "            'recall': grp_recall,\n",
    "            'f1': grp_f1,\n",
    "            'auc': grp_auc\n",
    "        }\n",
    "        with open(paths.results_base_path + f'group_results_{key}.txt', 'w') as f:\n",
    "            f.write(str(group_result))\n",
    "\n",
    "        all_patient_group_results[key].append(group_result)\n",
    "\n",
    "\n",
    "\n",
    "result_df = results_logger.to_dataframe()\n",
    "result_df.to_csv(paths.base_path + paths.folder_name + '\\\\results.csv')\n",
    "\n",
    "for key in all_patient_group_results.keys():\n",
    "    df_gp = pd.DataFrame(all_patient_group_results[key], index=settings.patient)\n",
    "    df_gp.to_csv(paths.base_path + paths.folder_name + f'\\\\group_results_{key}.csv')"
   ],
   "id": "f09686880764721c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "871e2780f398577f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "aefbb9db317e3d62",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e8eccfaf9514fefc",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
