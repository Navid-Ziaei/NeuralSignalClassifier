{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:35:56.015288800Z",
     "start_time": "2024-05-06T19:35:49.563863100Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.settings import Paths, Settings\n",
    "from src.data_loader import VerbMemEEGDataLoader, PilotEEGDataLoader, CLEARDataLoader\n",
    "from src.data_preprocess import DataPreprocessor\n",
    "from src.visualization.EEG_vissualizer import visualize_erp, visualize_block_ERP, visualize_feature_box_plot, \\\n",
    "    visualize_block_features\n",
    "from src.data_loader import EEGDataSet\n",
    "from src.feature_extraction import FeatureExtractor\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "import copy\n",
    "from src.experiments.utils.train_gplvm_utils import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:35:56.035602500Z",
     "start_time": "2024-05-06T19:35:56.019902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: all\n"
     ]
    }
   ],
   "source": [
    "# Load settings from settings.json\n",
    "settings = Settings()  # Initialize settings object\n",
    "settings.load_settings()  # Load settings from a JSON file\n",
    "\n",
    "# Set up paths for data\n",
    "paths = Paths(settings)  # Initialize paths object with loaded settings\n",
    "paths.load_device_paths()  # Load device-specific paths\n",
    "paths.create_paths()  # Create any necessary file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:36:00.189766600Z",
     "start_time": "2024-05-06T19:35:56.035602500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 0 from 12: 101_toi1gng_2023-11-20_14-09-06_1 Load Data\n",
      "Subject 1 from 12: 102_toi1gng_2023-11-14_13-59-28_1 Load Data\n",
      "Subject 2 from 12: 103_toi1gng_2023-11-29_13-35-36_1 Load Data\n",
      "Subject 3 from 12: 104_toi1gng_2023-11-30_14-45-53_1 Load Data\n",
      "Subject 4 from 12: 106_toi1gng_2023-12-05_10-01-06_1 Load Data\n",
      "Subject 5 from 12: 110_toi1gng2t_2024-01-05_13-10-01_1 Load Data\n",
      "Subject 6 from 12: 111_toi1gng2t_2024-01-09_11-59-24_1 Load Data\n",
      "Subject 7 from 12: 112_toi1gng2t_2024-02-02_13-58-25_1 Load Data\n",
      "Subject 8 from 12: 113_toi1gng2t_2024-02-01_14-34-31_1 Load Data\n",
      "Subject 9 from 12: 114_toi1gng2t_2024-01-23_14-25-05_1 Load Data\n",
      "Subject 10 from 12: 115_toi1gng2t_2024-02-07_15-04-03_1 Load Data\n",
      "Subject 11 from 12: 116_toi1gng_2023-12-07_14-09-10_1 Load Data\n"
     ]
    }
   ],
   "source": [
    "dataset = PilotEEGDataLoader(paths=paths, settings=settings)\n",
    "dataset.load_data(patient_ids=settings.patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "for i in range(12):\n",
    "    single_patient_data = dataset.all_patient_data[list(dataset.all_patient_data.keys())[i]]\n",
    "    label_df = pd.DataFrame(single_patient_data.labels)\n",
    "    block_index = (label_df['is_correct'] == True) & (label_df['stim'] != 'ctl')\n",
    "\n",
    "\n",
    "    data_dict = {\n",
    "        'data': single_patient_data.data[block_index],\n",
    "        'time_ms': single_patient_data.time_ms,\n",
    "        'block_id': label_df[block_index]['block_number'].values,\n",
    "        'block_type': label_df[block_index]['block_type'].values,\n",
    "        'is_experienced': label_df[block_index]['is_experienced'].values,\n",
    "        'is_resp': label_df[block_index]['is_resp'].values,\n",
    "        'is_correct': label_df[block_index]['is_correct'].values,\n",
    "        'go_nogo': label_df[block_index]['go_nogo'].values,\n",
    "        'fs': single_patient_data.fs,\n",
    "        'response_time': single_patient_data.response_time[block_index],\n",
    "        'file_name':single_patient_data.file_name\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    savemat(f'patient{single_patient_data.file_name.split(\"_\")[0]}.mat', data_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient101.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient102.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient103.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient104.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient106.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient110.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient111.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient112.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient113.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient114.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient115.pkl\n",
      "Data saved to G:\\.shortcut-targets-by-id\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\Pilot1\\patient116.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "for i in range(12):\n",
    "    single_patient_data = dataset.all_patient_data[list(dataset.all_patient_data.keys())[i]]\n",
    "    label_df = pd.DataFrame(single_patient_data.labels)\n",
    "    block_index = (label_df['is_correct'] == True) & (label_df['stim'] != 'ctl')\n",
    "\n",
    "\n",
    "    data_dict = {\n",
    "        'data': single_patient_data.data[block_index],\n",
    "        'time_ms': single_patient_data.time_ms,\n",
    "        'block_id': label_df[block_index]['block_number'].values,\n",
    "        'block_type': label_df[block_index]['block_type'].values,\n",
    "        'is_experienced': label_df[block_index]['is_experienced'].values,\n",
    "        'is_resp': label_df[block_index]['is_resp'].values,\n",
    "        'is_correct': label_df[block_index]['is_correct'].values,\n",
    "        'go_nogo': label_df[block_index]['go_nogo'].values,\n",
    "        'fs': single_patient_data.fs,\n",
    "        'response_time': single_patient_data.response_time[block_index],\n",
    "        'file_name':single_patient_data.file_name\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    # Define the file path\n",
    "    file_path = f'G:\\\\.shortcut-targets-by-id\\\\1cX90O_ArtclHDzk2LNzWWS9RYvVLVteA\\\\Pilot1\\\\patient{single_patient_data.file_name.split(\"_\")[0]}.pkl'\n",
    "\n",
    "    # Open a file and save the dictionary using pickle\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(data_dict, file)\n",
    "\n",
    "    print(f\"Data saved to {file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:36:31.215221600Z",
     "start_time": "2024-05-06T19:36:03.743457700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "single_patient_data.response_time[block_index]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "single_patient_data.file_name.split(\"_\")[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "1. remove_baseline(normalize=False, baseline_t_min=-1000)\n",
    "2. low_pass_filter(cutoff=45, order=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessor = DataPreprocessor(paths=paths, settings=settings)  # Initialize data preprocessor\n",
    "dataset = data_preprocessor.preprocess(dataset)  # Apply preprocessing steps to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient 101 Analysis\n",
    "- Step 1: We filter based on the correct asnwers\n",
    "- Step 2: We remove the ctl stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_patient_data = copy.copy(dataset.all_patient_data[list(dataset.all_patient_data.keys())[0]])\n",
    "print(f\"Selected patient is {single_patient_data.file_name.split('_')[0]}\")\n",
    "channels = single_patient_data.channel_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3\n",
    "-  Plot ERP in each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel_idx in enumerate(channels[:10]):\n",
    "    fig, _ = visualize_block_ERP(single_patient_data, stim='w', channel_idx=idx, axs=None, fig=None, show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify based on this features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_idx(time, start_time, end_time):\n",
    "    start_index = np.argmin(np.abs(time - start_time))\n",
    "    end_index = np.argmin(np.abs(time - end_time))\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = {}\n",
    "start_index, end_index = get_time_idx(single_patient_data.time_ms, 150, 250)\n",
    "time_features['n200'] = np.mean(single_patient_data.data[:, :, start_index:end_index], axis=-1)\n",
    "\n",
    "start_index, end_index = get_time_idx(single_patient_data.time_ms, 250, 500)\n",
    "time_features['p300'] = np.mean(single_patient_data.data[:, :, start_index:end_index], axis=-1)\n",
    "\n",
    "start_index, end_index = get_time_idx(single_patient_data.time_ms, 500, 750)\n",
    "time_features['post_300'] = np.mean(single_patient_data.data[:, :, start_index:end_index], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel_idx in enumerate(channels[:10]):\n",
    "    visualize_block_features(single_patient_data, time_features, channel_idx=idx, stim='w', fig=None, axs=None,show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. prepaire and spilit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = {}\n",
    "for key in time_features.keys():\n",
    "    for ch_idx, ch in enumerate(single_patient_data.channel_names):\n",
    "        training_features[key + ' ' + ch] = time_features[key][:,ch_idx]\n",
    "training_features_df = pd.DataFrame(training_features)\n",
    "training_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K fold training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kfold(X, y, model):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    folds = kf.split(X)\n",
    "    for fold_idx, (train_index, test_index) in enumerate(folds):\n",
    "        x_train, x_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(x_train, y_train)\n",
    "        predictions = model.predict(x_test)\n",
    "        print(predictions)\n",
    "        f1 = f1_score(y_test, predictions>=0.5, average='macro')\n",
    "        print(f\"F1-score: {f1 * 100:.2f}%\")\n",
    "\n",
    "        report = classification_report(y_true=y_test, y_pred=predictions>0.5)\n",
    "        print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Separate each block and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.utils.train_gplvm_utils import *\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "training_features = {}\n",
    "for key in time_features.keys():\n",
    "    for ch_idx, ch in enumerate(single_patient_data.channel_names):\n",
    "        training_features[key + ' ' + ch] = time_features[key][:,ch_idx]\n",
    "training_features_df = pd.DataFrame(training_features)\n",
    "training_features_df.head()\n",
    "\n",
    "stim = 'w'\n",
    "block_idx = np.unique(single_patient_data.labels['block_number'])\n",
    "label_df = pd.DataFrame(single_patient_data.labels)\n",
    "blocks = {idx: list(np.unique(label_df[label_df['block_number'] == idx]['block_type'])) for idx in block_idx}\n",
    "blocks_with_stim = [idx for idx, vals in blocks.items() if any(stim in val for val in vals)]\n",
    "\n",
    "\n",
    "for i in range(len(blocks_with_stim)):\n",
    "    print(f\"============ Block {blocks_with_stim[i]} {blocks[blocks_with_stim[i]]} ===============\")\n",
    "    block_index = (label_df['block_number'] == blocks_with_stim[i]) & (label_df['is_correct'] == True) & (\n",
    "            label_df['stim'] != 'ctl')\n",
    "    labels = {key: label_df[key][block_index].to_list() for key in label_df.columns.to_list()}\n",
    "    single_channel_feature_df = training_features_df[block_index.values].copy()\n",
    "    fs = single_patient_data.fs\n",
    "    time_ms = single_patient_data.time_ms\n",
    "    channel_names = single_patient_data.channel_names\n",
    "    file_name = single_patient_data.file_name\n",
    "    single_channel_feature_df.head()\n",
    "    model = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=2)\n",
    "    model = linear_model.Lasso(alpha=1)\n",
    "    model = SVC()\n",
    "    train_kfold(X=single_channel_feature_df, y=np.array(labels['is_experienced']))\n",
    "\n",
    "print(f\"============ Combined Blocks ===============\")\n",
    "block_index = label_df['block_number'].isin(blocks_with_stim) & \\\n",
    "                  (label_df['is_correct'] == True) & \\\n",
    "                  (label_df['stim'] != 'ctl')\n",
    "labels = {key: label_df[key][block_index].to_list() for key in label_df.columns.to_list()}\n",
    "single_channel_feature_df = training_features_df[block_index.values].copy()\n",
    "fs = single_patient_data.fs\n",
    "time_ms = single_patient_data.time_ms\n",
    "channel_names = single_patient_data.channel_names\n",
    "file_name = single_patient_data.file_name\n",
    "single_channel_feature_df.head()\n",
    "\n",
    "train_kfold(X=single_channel_feature_df, y=np.array(labels['is_experienced']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: find p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "channel_idx = 2\n",
    "stim = 'w'\n",
    "\n",
    "channel_name = single_patient_data.channel_names[channel_idx]\n",
    "block_idx = np.unique(single_patient_data.labels['block_number'])\n",
    "label_df = pd.DataFrame(single_patient_data.labels)\n",
    "\n",
    "# specify blocks with a stim 'w' or 'i'\n",
    "blocks = {idx: list(np.unique(label_df[label_df['block_number'] == idx]['block_type'])) for idx in block_idx}\n",
    "blocks_with_stim = [idx for idx, vals in blocks.items() if any(stim in val for val in vals)]\n",
    "\n",
    "#select specific channel\n",
    "time_feature_df = pd.DataFrame({key: time_features[key][:, channel_idx] for key in time_features.keys()})\n",
    "\n",
    "hue_column = 'is_experienced'\n",
    "palette = {True: \"green\", False: \"red\"}\n",
    "# Bar plot data preparation\n",
    "results = []\n",
    "\n",
    "for block in blocks_with_stim:\n",
    "    block_data = label_df[label_df['block_number'] == block]\n",
    "    block_data = block_data[block_data['is_correct'] & (block_data['stim'] != 'ctl')]\n",
    "    single_channel_feature_df = time_feature_df.loc[block_data.index]\n",
    "    single_channel_feature_df['is_experienced'] = block_data['is_experienced']\n",
    "\n",
    "    for feature_name, data in single_channel_feature_df.items():\n",
    "        if feature_name == 'is_experienced':\n",
    "            continue\n",
    "        exp = data[block_data['is_experienced']]\n",
    "        inexp = data[~block_data['is_experienced']]\n",
    "\n",
    "        t_stat, p_val = ttest_ind(exp.dropna(), inexp.dropna(), equal_var=False)\n",
    "        results.append({\n",
    "            'Block': f'Block {block}',\n",
    "            'Feature': feature_name,\n",
    "            'P-Value': p_val,\n",
    "            'T-Statistic': t_stat\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Feature', y='P-Value', hue='Block', data=results_df,\n",
    "            palette=np.where(results_df['T-Statistic'] > 0, 'blue', 'red'))\n",
    "#plt.yscale('log')  # Log scale for better visibility if small p-values are present\n",
    "plt.title(f'P-Values by Block and Feature for {channel_name}')\n",
    "plt.ylabel('P-Value (log scale)')\n",
    "plt.xlabel('Feature')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Channel Groups\n",
    "### Channel groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels = single_patient_data.channel_names\n",
    "channel_groups = {\n",
    "        \"CF\": ['C15', 'C16', 'C17', 'C18', 'C19', 'C28', 'C29'],\n",
    "        \"LAL\": ['B30', 'B31', 'D5', 'D6', 'D7', 'D8', 'D9'],\n",
    "        \"LAM\": ['D2', 'D3', 'D4', 'D12', 'D13', 'C24', 'C25'],\n",
    "        \"RAM\": ['C2', 'C3', 'C4', 'C11', 'C12', 'B31', 'B32'],\n",
    "        \"RAL\": ['C5', 'C6', 'C7', 'C8', 'C9', 'B27', 'B28'],\n",
    "        \"LOT\": ['A10', 'A11', 'D26', 'D27', 'D30', 'D31', 'D32'],\n",
    "        \"LPM\": ['A5', 'A6', 'A7', 'A18', 'D16', 'D17', 'D28'],\n",
    "        \"RPM\": ['A31', 'A32', 'B2', 'B3', 'B4', 'B18', 'B19'],\n",
    "        \"ROT\": ['B7', 'B8', 'B10', 'B11', 'B12', 'B16', 'B17'],\n",
    "        \"CO\": ['A14', 'A15', 'A22', 'A23', 'A24', 'A27', 'A28']}\n",
    "\n",
    "channel_groups_indices = {group: [all_channels.index(channel) for channel in channels_name] for group, channels_name in channel_groups.items()}\n",
    "for group_name, indices in channel_groups_indices.items():\n",
    "    print(f\"{group_name}: {indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Use the average of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_patient_data_group_avg = EEGDataSet()\n",
    "new_channel_names, new_data = [], []\n",
    "for group_name, channel_indices in channel_groups_indices.items():\n",
    "    print(f\"group {group_name}: {[all_channels[ch - 1] for ch in channel_indices]}\")\n",
    "    new_data.append(np.mean(single_patient_data.data[:, np.array(channel_indices), :], axis=1, keepdims=True))\n",
    "    new_channel_names.append(group_name)\n",
    "new_data = np.concatenate(new_data, axis=1)\n",
    "single_patient_data_group_avg.data = new_data\n",
    "single_patient_data_group_avg.channel_names = new_channel_names\n",
    "single_patient_data_group_avg.fs = single_patient_data.fs\n",
    "single_patient_data_group_avg.labels = single_patient_data.labels\n",
    "single_patient_data_group_avg.file_name = single_patient_data.file_name\n",
    "single_patient_data_group_avg.time_ms = single_patient_data.time_ms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the ERP in Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel_idx in enumerate(new_channel_names):\n",
    "    fig, _ = visualize_block_ERP(single_patient_data_group_avg, stim='w', channel_idx=idx, axs=None, fig=None, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_group_avg = {}\n",
    "start_index, end_index = get_time_idx(single_patient_data_group_avg.time_ms, 150, 250)\n",
    "time_features_group_avg['n200'] = np.mean(single_patient_data_group_avg.data[:, :, start_index:end_index], axis=-1)\n",
    "\n",
    "start_index, end_index = get_time_idx(single_patient_data_group_avg.time_ms, 250, 500)\n",
    "time_features_group_avg['p300'] = np.mean(single_patient_data_group_avg.data[:, :, start_index:end_index], axis=-1)\n",
    "\n",
    "start_index, end_index = get_time_idx(single_patient_data_group_avg.time_ms, 500, 750)\n",
    "time_features_group_avg['post_300'] = np.mean(single_patient_data_group_avg.data[:, :, start_index:end_index], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel_idx in enumerate(single_patient_data_group_avg.channel_names):\n",
    "    visualize_block_features(single_patient_data_group_avg, time_features_group_avg, channel_idx=idx, stim='w', fig=None, axs=None,show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_gp_avg = {}\n",
    "for key in time_features.keys():\n",
    "    for ch_idx, ch in enumerate(single_patient_data_group_avg.channel_names):\n",
    "        training_features_gp_avg[key + ' ' + ch] = time_features_group_avg[key][:,ch_idx]\n",
    "training_features_df_gp_avg = pd.DataFrame(training_features_gp_avg)\n",
    "training_features_df_gp_avg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.utils.train_gplvm_utils import *\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "stim = 'i'\n",
    "block_idx = np.unique(single_patient_data.labels['block_number'])\n",
    "label_df = pd.DataFrame(single_patient_data.labels)\n",
    "blocks = {idx: list(np.unique(label_df[label_df['block_number'] == idx]['block_type'])) for idx in block_idx}\n",
    "blocks_with_stim = [idx for idx, vals in blocks.items() if any(stim in val for val in vals)]\n",
    "\n",
    "\n",
    "for i in range(len(blocks_with_stim)):\n",
    "    print(f\"============ Block {blocks_with_stim[i]} {blocks[blocks_with_stim[i]]} ===============\")\n",
    "    block_index = (label_df['block_number'] == blocks_with_stim[i]) & (label_df['is_correct'] == True) & (\n",
    "            label_df['stim'] != 'ctl')\n",
    "    labels = {key: label_df[key][block_index].to_list() for key in label_df.columns.to_list()}\n",
    "    single_channel_feature_df = training_features_df[block_index.values].copy()\n",
    "    fs = single_patient_data.fs\n",
    "    time_ms = single_patient_data.time_ms\n",
    "    channel_names = single_patient_data.channel_names\n",
    "    file_name = single_patient_data.file_name\n",
    "    single_channel_feature_df.head()\n",
    "\n",
    "    train_kfold(X=single_channel_feature_df, y=np.array(labels['is_experienced']))\n",
    "\n",
    "print(f\"============ Combined Blocks ===============\")\n",
    "block_index = label_df['block_number'].isin(blocks_with_stim) & \\\n",
    "                  (label_df['is_correct'] == True) & \\\n",
    "                  (label_df['stim'] != 'ctl')\n",
    "labels = {key: label_df[key][block_index].to_list() for key in label_df.columns.to_list()}\n",
    "single_channel_feature_df = training_features_df[block_index.values].copy()\n",
    "fs = single_patient_data.fs\n",
    "time_ms = single_patient_data.time_ms\n",
    "channel_names = single_patient_data.channel_names\n",
    "file_name = single_patient_data.file_name\n",
    "single_channel_feature_df.head()\n",
    "\n",
    "train_kfold(X=single_channel_feature_df, y=np.array(labels['is_experienced']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: Use the eigen vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 128Hz sampling rate is too much. It's better to use the lower sampling rate. So we Filter the data with a lowpass filter wirh cutoff frequency of 15Hz and then downsample it to 30Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample_poly, butter, filtfilt\n",
    "\n",
    "def resample(single_patient_data, f_resample, anti_alias_filter=False):\n",
    "    # Compute resampling factor\n",
    "    # Compute resampling factor\n",
    "    resample_factor = single_patient_data.fs // f_resample\n",
    "\n",
    "    # Design a low-pass anti-aliasing filter\n",
    "    nyquist_freq = 0.5 * single_patient_data.fs\n",
    "    cutoff_freq = 0.5 * f_resample\n",
    "    b, a = butter(4, cutoff_freq / nyquist_freq, btype='low')\n",
    "\n",
    "    if anti_alias_filter is True:\n",
    "        # Apply the anti-aliasing filter to EEG signal\n",
    "        filtered_signal = filtfilt(b, a, single_patient_data.data, axis=-1)\n",
    "    else:\n",
    "        filtered_signal = single_patient_data.data\n",
    "\n",
    "    # Resample the EEG signal\n",
    "    resampled_signal = resample_poly(filtered_signal, 1, resample_factor, axis=-1)\n",
    "\n",
    "    # Resample the time vector\n",
    "    resampled_time_ms = resample_poly(single_patient_data.time_ms, 1, resample_factor)\n",
    "\n",
    "    single_patient_data.data = resampled_signal\n",
    "    single_patient_data.time_ms = resampled_time_ms\n",
    "    single_patient_data.fs = f_resample\n",
    "\n",
    "    return single_patient_data\n",
    "\n",
    "def remove_baseline(single_patient_data, baseline_t_min=-300, baseline_t_max=0, normalize=True):\n",
    "\n",
    "    # Determine start and end indices for the baseline time window\n",
    "    idx_start = np.argmin(np.abs(single_patient_data.time_ms - baseline_t_min))\n",
    "    idx_end = np.argmin(np.abs(single_patient_data.time_ms - baseline_t_max))\n",
    "\n",
    "    if (idx_end - idx_start) > 5:\n",
    "        # Calculate the baseline mean values for each trial and channel\n",
    "        baseline_means = np.mean(single_patient_data.data[:, :, idx_start:idx_end], axis=2, keepdims=True)\n",
    "\n",
    "        # Subtract the baseline mean from all time points for each trial and channel\n",
    "        eeg_data_baseline_removed = single_patient_data.data - baseline_means\n",
    "\n",
    "        if normalize is True:\n",
    "            maximum = np.quantile(np.abs(eeg_data_baseline_removed[:, :, idx_start:idx_end]),\n",
    "                                  0.99, axis=2, keepdims=True)\n",
    "            eeg_data_baseline_removed = eeg_data_baseline_removed / maximum\n",
    "    single_patient_data.data = eeg_data_baseline_removed\n",
    "\n",
    "    return eeg_data_baseline_removed\n",
    "\n",
    "def low_pass_filter(single_patient_data, cutoff=10, order=5):\n",
    "    # Compute filter coefficients\n",
    "    nyq = 0.5 * single_patient_data.fs  # Nyquist Frequency\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(N=order, Wn=normal_cutoff, btype='low', analog=False)\n",
    "\n",
    "    # Apply the filter to the signal\n",
    "    filtered_signal = filtfilt(b, a, single_patient_data.data)\n",
    "    single_patient_data.data = filtered_signal\n",
    "\n",
    "    return single_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "single_patient_data_lp = copy.copy(dataset.all_patient_data[list(dataset.all_patient_data.keys())[0]])\n",
    "print(f\"Selected patient is {single_patient_data_lp.file_name.split('_')[0]}\")\n",
    "channels = single_patient_data_lp.channel_names\n",
    "\n",
    "\n",
    "single_patient_data_lp = low_pass_filter(single_patient_data_lp, cutoff=15, order=5)\n",
    "single_patient_data_lp = resample(single_patient_data_lp, f_resample=30, anti_alias_filter=False)\n",
    "# single_patient_data_lp = remove_baseline(single_patient_data_lp, baseline_t_min=-1000, baseline_t_max=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the eign vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "componenet = 0\n",
    "\n",
    "single_patient_data_group_egn = EEGDataSet()\n",
    "new_channel_names, new_data = [], []\n",
    "for group_name, channel_indices in channel_groups_indices.items():\n",
    "    print(f\"group {group_name}: {[all_channels[ch - 1] for ch in channel_indices]}\")\n",
    "    group = single_patient_data.data[:, np.array(channel_indices), :]\n",
    "    new_data_channel = []\n",
    "    for i in range(single_patient_data_lp.data.shape[0]):\n",
    "        X = single_patient_data_lp.data[i, np.array(channel_indices), :]\n",
    "\n",
    "        # Standardizing the data\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        pca = PCA(n_components=4)\n",
    "        pca.fit(group[i])\n",
    "        new_data_channel.append(pca.components_[componenet])\n",
    "    new_data_channel = np.stack(new_data_channel, axis=0)\n",
    "    new_data.append(new_data_channel[:, np.newaxis, :])\n",
    "    new_channel_names.append(group_name)\n",
    "new_data = np.concatenate(new_data, axis=1)\n",
    "single_patient_data_group_egn.data = new_data\n",
    "single_patient_data_group_egn.channel_names = new_channel_names\n",
    "single_patient_data_group_egn.fs = single_patient_data.fs\n",
    "single_patient_data_group_egn.labels = single_patient_data.labels\n",
    "single_patient_data_group_egn.file_name = single_patient_data.file_name\n",
    "single_patient_data_group_egn.time_ms = single_patient_data_lp.time_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel_idx in enumerate(new_channel_names):\n",
    "    fig, _ = visualize_block_ERP(single_patient_data_group_egn, stim='w', channel_idx=idx, axs=None, fig=None, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_group_egn = {}\n",
    "start_index, end_index = get_time_idx(single_patient_data_group_egn.time_ms, 150, 250)\n",
    "time_features_group_egn['n200'] = np.mean(single_patient_data_group_egn.data[:, :, start_index:end_index], axis=-1)\n",
    "\n",
    "start_index, end_index = get_time_idx(single_patient_data_group_egn.time_ms, 250, 500)\n",
    "time_features_group_egn['p300'] = np.mean(single_patient_data_group_egn.data[:, :, start_index:end_index], axis=-1)\n",
    "\n",
    "start_index, end_index = get_time_idx(single_patient_data_group_egn.time_ms, 500, 750)\n",
    "time_features_group_egn['post_300'] = np.mean(single_patient_data_group_egn.data[:, :, start_index:end_index], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel_idx in enumerate(single_patient_data_group_egn.channel_names):\n",
    "    visualize_block_features(single_patient_data_group_egn, time_features_group_egn, channel_idx=idx, stim='w', fig=None, axs=None,show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_features = {}\n",
    "for key in time_features.keys():\n",
    "    for ch_idx, ch in enumerate(single_patient_data.channel_names):\n",
    "        training_features[key + ' ' + ch] = time_features[key][:,ch_idx]\n",
    "training_features_df = pd.DataFrame(training_features)\n",
    "training_features_df.head()\n",
    "\n",
    "stim = 'w'\n",
    "block_idx = np.unique(single_patient_data.labels['block_number'])\n",
    "label_df = pd.DataFrame(single_patient_data.labels)\n",
    "blocks = {idx: list(np.unique(label_df[label_df['block_number'] == idx]['block_type'])) for idx in block_idx}\n",
    "blocks_with_stim = [idx for idx, vals in blocks.items() if any(stim in val for val in vals)]\n",
    "\n",
    "\n",
    "for i in range(len(blocks_with_stim)):\n",
    "    print(f\"============ Block {blocks_with_stim[i]} {blocks[blocks_with_stim[i]]} ===============\")\n",
    "    block_index = (label_df['block_number'] == blocks_with_stim[i]) & (label_df['is_correct'] == True) & (\n",
    "            label_df['stim'] != 'ctl')\n",
    "    labels = {key: label_df[key][block_index].to_list() for key in label_df.columns.to_list()}\n",
    "    single_channel_feature_df = training_features_df[block_index.values].copy()\n",
    "    fs = single_patient_data.fs\n",
    "    time_ms = single_patient_data.time_ms\n",
    "    channel_names = single_patient_data.channel_names\n",
    "    file_name = single_patient_data.file_name\n",
    "    single_channel_feature_df.head()\n",
    "\n",
    "    model = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=2)\n",
    "    model = linear_model.Lasso(alpha=1)\n",
    "    model = SVC()\n",
    "    train_kfold(X=single_channel_feature_df, y=np.array(labels['is_experienced']), model = model)\n",
    "\n",
    "print(f\"============ Combined Blocks ===============\")\n",
    "block_index = label_df['block_number'].isin(blocks_with_stim) & \\\n",
    "                  (label_df['is_correct'] == True) & \\\n",
    "                  (label_df['stim'] != 'ctl')\n",
    "labels = {key: label_df[key][block_index].to_list() for key in label_df.columns.to_list()}\n",
    "single_channel_feature_df = training_features_df[block_index.values].copy()\n",
    "fs = single_patient_data.fs\n",
    "time_ms = single_patient_data.time_ms\n",
    "channel_names = single_patient_data.channel_names\n",
    "file_name = single_patient_data.file_name\n",
    "single_channel_feature_df.head()\n",
    "\n",
    "model = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=2)\n",
    "model = linear_model.Lasso(alpha=1)\n",
    "model = SVC()\n",
    "train_kfold(X=single_channel_feature_df, y=np.array(labels['is_experienced']), model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
